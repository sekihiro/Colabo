{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_pre-trained-models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPHWkB+FpEI8vunyPuZYPBl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sekihiro/Colabo/blob/master/bert_pre_trained_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC5YNGbxViQv",
        "colab_type": "text"
      },
      "source": [
        "# 【PyTorch】BERTの使い方 - 日本語pre-trained models\n",
        "- 事前学習した日本語pre-trained modelsの精度を確認します。\n",
        "- 今回はMasked Language Modelの精度を確認します。\n",
        "- Masked Language Modelを簡単に説明すると、文の中のある単語をマスクしておき、そのマスクされた単語を予測するというものです。\n",
        "- https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWsrRMIBVkur",
        "colab_type": "code",
        "outputId": "649ff74b-fb01-4548-de76-2aea8a350895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR68icBjWDtL",
        "colab_type": "text"
      },
      "source": [
        "## defaultでインストールされていないライブラリを入れる\n",
        "- MeCab と transformers(旧名：pytorch-pretrained-BERT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efr4YY64WUMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MeCab\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzrJPlJQWUD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformers(旧名：pytorch-pretrained-BERT)\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jlDc18EV5Tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b13f0632-728b-490c-ce76-eacffe75b42d"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM, BertForSequenceClassification"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFg5cxAqIytE",
        "colab_type": "text"
      },
      "source": [
        "## tokenizer と model の取得\n",
        "- 東北大学 乾・鈴木研究室の作成・公開されたBERTモデル\n",
        "- 公開されているモデルは４種類あるが、bert-base-japanese-whole-word-masking を使うのが良い\n",
        "- 日本語Wikipediaを用いて学習\n",
        "- okenizerはMeCab + WordPiece（character tokenizationもある）\n",
        "- max sequence lengthは512\n",
        "- https://qiita.com/nekoumei/items/7b911c61324f16c43e7e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4HYNme703gB",
        "colab_type": "text"
      },
      "source": [
        "### transformers で定義されているクラス\n",
        "- http://kento1109.hatenablog.com/entry/2019/08/20/161936\n",
        "- BertForMaskedLM : 単語を出力するためのクラス\n",
        "- BertForSequenceClassification : 分類問題のためのクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW_KQMG5DWW-",
        "colab_type": "code",
        "outputId": "2886b1e0-a61c-4eec-9fa5-6698397e5745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "BASE_PATH = \"/content/drive/My Drive/git/\"\n",
        "MODEL_PATH = BASE_PATH + 'model/bert/base-japanese-whole-word-masking/'\n",
        "\n",
        "if os.path.isfile(MODEL_PATH + 'vocab.txt'):\n",
        "    print('loading bert-pytorch_tokenizer ..... ')\n",
        "    tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_PATH)\n",
        "else:\n",
        "    print('downloading bert-pytorch_tokenizer ..... ')\n",
        "    tokenizer = BertJapaneseTokenizer.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "    tokenizer.save_pretrained(MODEL_PATH)\n",
        "\n",
        "if os.path.isfile(MODEL_PATH + 'pytorch_model.bin'):\n",
        "    print('loading bert-pytorch_model ..... ')\n",
        "    model = BertForMaskedLM.from_pretrained(MODEL_PATH)\n",
        "else:\n",
        "    print('downloading bert-pytorch_model ..... ')\n",
        "    model = BertForMaskedLM.from_pretrained('bert-base-japanese-whole-word-masking')\n",
        "    model.save_pretrained(MODEL_PATH)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading bert-pytorch_tokenizer ..... \n",
            "loading bert-pytorch_model ..... \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3OGfwkhVlGB",
        "colab_type": "code",
        "outputId": "ef5b5ea4-86e9-456f-b0ae-794a42ee9e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Tokenize input\n",
        "text = 'テレビでサッカーの試合を見る。'\n",
        "#text = '今日は仕事で疲れたので、飲んで帰った。'\n",
        "print(text)\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "# ['テレビ', 'で', 'サッカー', 'の', '試合', 'を', '見る', '。']\n",
        "\n",
        "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
        "masked_index = 2\n",
        "tmp = ''\n",
        "for i, buf in enumerate(tokenized_text):\n",
        "    if i == masked_index:\n",
        "        tmp = tmp + '[MASK]'\n",
        "    else:\n",
        "        tmp = tmp + tokenized_text[i]\n",
        "print(tmp)\n",
        "tokenized_text[masked_index] = '[MASK]'\n",
        "# ['テレビ', 'で', '[MASK]', 'の', '試合', 'を', '見る', '。']\n",
        "\n",
        "# Convert token to vocabulary indices\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "# [571, 12, 4, 5, 608, 11, 2867, 8]\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "# tensor([[ 571,   12,    4,    5,  608,   11, 2867,    8]])\n",
        "\n",
        "# Predict\n",
        "model.eval()\n",
        "with torch.no_grad(): # 必要のない計算を停止 パラメータの保存を止める\n",
        "    outputs = model(tokens_tensor)\n",
        "    ##### outputs ===> [1, 8, 32000]\n",
        "    #pprint.pprint(outputs)\n",
        "    #pprint.pprint(outputs[0])\n",
        "    #pprint.pprint(outputs[0][0])\n",
        "    #pprint.pprint(outputs[0][0][masked_index]) # [MASK]の部分の予測値を得る\n",
        "    predictions = outputs[0][0][masked_index].topk(10) # 予測結果の上位N件を抽出(値とインデックスを得る)\n",
        "    #print('----------')\n",
        "    #pprint.pprint(predictions)\n",
        "\n",
        "# Show results\n",
        "print('----------\\n[MASK]')\n",
        "for i, index_t in enumerate(predictions.indices): # インデックスのみ採用\n",
        "    index = index_t.item() # tensor -> int\n",
        "    token = tokenizer.convert_ids_to_tokens([index])[0]\n",
        "    print(i, token)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "テレビでサッカーの試合を見る。\n",
            "テレビで[MASK]の試合を見る。\n",
            "----------\n",
            "[MASK]\n",
            "0 クリケット\n",
            "1 タイガース\n",
            "2 サッカー\n",
            "3 メッツ\n",
            "4 カブス\n",
            "5 の\n",
            "6 ライオンズ\n",
            "7 レッズ\n",
            "8 ヤンキース\n",
            "9 ジャイアンツ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rzh_yVyDBEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}